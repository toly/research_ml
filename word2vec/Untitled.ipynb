{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T18:30:53.831104Z",
     "start_time": "2018-05-22T18:30:53.810990Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, Input, Dot, Multiply, Lambda\n",
    "from keras.layers import dot\n",
    "# from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T09:35:57.454561Z",
     "start_time": "2018-05-22T09:35:57.448986Z"
    }
   },
   "outputs": [],
   "source": [
    "WORD_RE = re.compile(r'[a-z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T09:31:36.839763Z",
     "start_time": "2018-05-22T09:31:36.557626Z"
    }
   },
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T09:31:40.975724Z",
     "start_time": "2018-05-22T09:31:40.970489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target_names', 'data', 'filenames', 'description', 'DESCR', 'target'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T09:34:06.879834Z",
     "start_time": "2018-05-22T09:34:06.826763Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = list(map(lambda x: x.lower(), data['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T09:42:29.386536Z",
     "start_time": "2018-05-22T09:42:27.225339Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCABULARY = []\n",
    "for text in texts:\n",
    "    VOCABULARY += WORD_RE.findall(text)\n",
    "counter = Counter(VOCABULARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY = [word for word, _ in counter.most_common(10000)]\n",
    "VOCABULARY.sort()\n",
    "VOCABULARY.insert(0, 'UNKNOWN')\n",
    "WORD2IND = {word: i for i, word in enumerate(VOCABULARY)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T11:12:32.250021Z",
     "start_time": "2018-05-22T11:12:32.242698Z"
    }
   },
   "outputs": [],
   "source": [
    "INDEXES = list(range(len(VOCABULARY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T18:32:45.297624Z",
     "start_time": "2018-05-22T18:32:45.199557Z"
    }
   },
   "outputs": [],
   "source": [
    "word_input = Input(shape=(1, ))\n",
    "word_embedding = Embedding(input_dim=len(VOCABULARY), output_dim=300)(word_input)\n",
    "\n",
    "context_input = Input(shape=(1, ))\n",
    "context_embedding = Embedding(input_dim=len(VOCABULARY), output_dim=300)(context_input)\n",
    "\n",
    "merge = Dot(axes=2)([context_embedding, word_embedding])\n",
    "t_slice = Lambda(lambda x: x[:, 0, :])(merge)\n",
    "target = Dense(1, activation='sigmoid')(t_slice)\n",
    "\n",
    "model = Model(inputs=[word_input, context_input], outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T18:32:45.758836Z",
     "start_time": "2018-05-22T18:32:45.663651Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T11:14:44.277842Z",
     "start_time": "2018-05-22T11:13:18.340322Z"
    }
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5\n",
    "\n",
    "inputs = []\n",
    "contexts = []\n",
    "targets = []\n",
    "for text in texts:\n",
    "    for sentence in text.split('.'):\n",
    "        words = WORD_RE.findall(sentence)\n",
    "        words_indexes = [WORD2IND.get(word, 0) for word in words]\n",
    "        for i in range(len(words_indexes)):\n",
    "            words_sample = words_indexes[max(0, i - WINDOW_SIZE): i + WINDOW_SIZE]\n",
    "            words_sample = [ind for ind in words_sample if ind != words_indexes[i]]\n",
    "            \n",
    "            if not words_sample:\n",
    "                continue\n",
    "            \n",
    "            # add positive\n",
    "            inputs.append([words_indexes[i]])\n",
    "            contexts.append([random.choice(words_sample)])\n",
    "            targets.append(1)\n",
    "            \n",
    "            # add negatives\n",
    "            for j in range(5):\n",
    "                inputs.append([words_indexes[i]])\n",
    "                contexts.append([random.choice(INDEXES)])\n",
    "                targets.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185941288"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array(inputs, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T11:20:00.737110Z",
     "start_time": "2018-05-22T11:19:41.328022Z"
    }
   },
   "outputs": [],
   "source": [
    "contexts = np.array(contexts, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T18:33:35.449254Z",
     "start_time": "2018-05-22T18:33:35.446116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20735898/20735898 [==============================] - 617s 30us/step - loss: 0.2207 - acc: 0.9232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2f06e93c8>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([inputs, contexts], targets, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get and store embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = model.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = embedding_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = {\n",
    "    'weights': embedding_weights,\n",
    "    'vocabulary': VOCABULARY,\n",
    "    'word2index': WORD2IND,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/word2vec.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/word2vec.pkl', 'rb') as f:\n",
    "    word2vec = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VOCABULARY.index('wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = np.dot(embedding_weights, embedding_weights[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_indexes = similarity.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blindly\n",
      "raider\n",
      "complaining\n",
      "wrong\n",
      "retract\n",
      "heal\n",
      "wondering\n",
      "warned\n",
      "mistaken\n",
      "hoped\n"
     ]
    }
   ],
   "source": [
    "for i in similar_indexes:\n",
    "    print(VOCABULARY[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: aa888@freenet.carleton.ca (mark baker)\n",
      "subject: re: the arrogance of christians\n",
      "reply-to: aa888@freenet.carleton.ca (mark baker)\n",
      "organization: the national capital freenet\n",
      "lines: 22\n",
      "\n",
      "in a previous article, mhsu@lonestar.utsa.edu (melinda . hsu) says:\n",
      "\n",
      ">\n",
      ">well the argument usually stops right there.  in the end,\n",
      ">aren't we all just kids, groping for the truth?  if so, do we have\n",
      ">the authority to declare all other beliefs besides our own as\n",
      ">false?\n",
      ">\n",
      "\n",
      "if i don't think my belief is right and everyone else's belief is wrong,\n",
      "then i don't have a belief. this is simply what belief means. where does\n",
      "the authority for a belief come from? nowhere, for a belief is itself\n",
      "authoratative. if i produce authority for a belief, where will i find\n",
      "authority for my belief in the legitimacy of the authority. in short, \n",
      "the mind has to start somewhere. (by the way, the majority of christians,\n",
      "i.e. catholics, believe in the authority of the church, and derive the\n",
      "authority of the bible from its acceptance by the church.)\n",
      "-- \n",
      "==============================================================================\n",
      "mark baker                  | \"the task ... is not to cut down jungles, but \n",
      "aa888@freenet.carleton.ca   | to irrigate deserts.\" -- c. s. lewis\n",
      "==============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    if 'utsa' in text:\n",
    "        print(text)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: lerxst@wam.umd.edu (where's my thing)\n",
      "subject: what car is this!?\n",
      "nntp-posting-host: rac3.wam.umd.edu\n",
      "organization: university of maryland, college park\n",
      "lines: 15\n",
      "\n",
      " i was wondering if anyone out there could enlighten me on this car i saw\n",
      "the other day. it was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. it was called a bricklin. the doors were really small. in addition,\n",
      "the front bumper was separate from the rest of the body. this is \n",
      "all i know. if anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "thanks,\n",
      "- il\n",
      "   ---- brought to you by your neighborhood lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
